[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "trove-newspaper-harvester",
    "section": "",
    "text": "View the full documentation\nThe Trove Newspaper (& Gazette) Harvester makes it easy to download large quantities of digitised articles from Trove’s newspapers and gazettes. Just give it a search from the Trove web interface, and the harvester will save the metadata of all the articles in a CSV (spreadsheet) file for further analysis. You can also save the full text of every article, as well as copies of the articles as JPG images, and even PDFs. While the web interface will only show you the first 2,000 results matching your search, the Newspaper Harvester will get everything."
  },
  {
    "objectID": "index.html#no-installation-required",
    "href": "index.html#no-installation-required",
    "title": "trove-newspaper-harvester",
    "section": "No installation required!",
    "text": "No installation required!\nIf you want to use the harvester without installing anything, just head over to the Trove Newspaper Harvester section in my GLAM Workbench."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "trove-newspaper-harvester",
    "section": "Installation",
    "text": "Installation\npip install trove-newspaper-harvester\nBefore you do any harvesting you need to get yourself a Trove API key."
  },
  {
    "objectID": "index.html#use-as-a-library",
    "href": "index.html#use-as-a-library",
    "title": "trove-newspaper-harvester",
    "section": "Use as a library",
    "text": "Use as a library\nfrom trove_newspaper_harvester.core import prepare_query, Harvester\nGenerate a set of query parameters using prepare_query.\nmy_query = \"https://trove.nla.gov.au/search/category/newspapers?keyword=wragge\"\nmy_api_key = \"mYSecREtkEy\"\n\nmy_query_params = prepare_query(query=my_query)\nInitialise the Harvester with your query parameters and api key.\nharvester = Harvester(query_params=my_query_params, key=my_api_key)\nStart the harvest!\nharvester.harvest()\nIf the harvest fails just run Harvester.harvest again.\nSee the core module documentation for more options and examples."
  },
  {
    "objectID": "index.html#use-as-a-command-line-tool",
    "href": "index.html#use-as-a-command-line-tool",
    "title": "trove-newspaper-harvester",
    "section": "Use as a command-line tool",
    "text": "Use as a command-line tool\nThere are three basic commands:\n\nstart – start a new harvest\nrestart – restart a stalled harvest\nreport – view harvest details\n\n\nStart a harvest\nTo start a new harvest you can just do:\ntroveharvester start \"[Trove query]\" [Trove API key]\nThe Trove query can either be a url copied and pasted from a search in the Trove web interface, or a Trove API query url constructed using something like the Trove API Console. Enclose the url in double quotes.\nSee the CLI module documentation for more details.\n\nCreated by Tim Sherratt for the GLAM Workbench. Support this project by becoming a GitHub sponsor."
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source\n\nHarvester\n\n Harvester (query_params=None, key=None, data_dir='data',\n            harvest_dir=None, config_file=None, text=False, pdf=False,\n            image=False, include_linebreaks=False, maximum=None)\n\nHarvest large quantities of digitised newspaper articles from Trove. Note that you must supply either query_params and key or config_file.\nParameters:\n\nquery_params [optional, dictionary of parameters]\nkey [optional, Trove API key]\nconfig_file [optional, path to a config file]\ndata_dir [optional, directory for harvests, string]\nharvest_dir [optional, directory for this harvest, string]\ntext [optional, save articles as text files, True or False]\npdf [optional, save articles as PDFs, True or False]\nimage [optional, save articles as images, True or False]\ninclude_linebreaks [optional, include linebreaks in text files, True or False]\nmaximum [optional, maximum number of results, integer]\n\nThe Harvester class configures and runs your harvest, saving results in a variety of formats.\nYou must supply either query_params and key, or the path to a config_file. If you don’t you’ll get a NoQueryError.\nBy default, the harvester will save harvests in a directory called data, with each individual harvest in a directory named according to the current date and time (YYYYMMDDHHmmss format). You can change this by setting the data_dir and harvest_dir parameters. This can help you to manage your harvests by grouping together related searches, or giving them meaningful names.\nThe harvester generates three data files by default:\n\nharvester_config.json a file that captures the parameters used to launch the harvest\nro-crate-metadata.json a metadata file documenting the harvest in RO-Crate format\nresults.ndjson contains details of all the harvested articles in a newline delimited JSON format (each line is a JSON object)\n\nYou can convert the ndjson file to a CSV format using Harvester.save_csv.\nThe text, pdf, and image options give you the option to save the contents of the articles as either text files, PDF files, or JPG images. Note that saving PDFs and images can be very slow.\nIf you only want to harvest part of the results set you can set the maximum parameter to the number of records you want.\n\n\nQuick start\n\nYou’ll need a Trove API key to use the harvester.\nJust copy the url from a search in the newspapers and gazettes category.\n\nfrom trove_newspaper_harvester.core import prepare_query, Harvester\n\nmy_api_key = \"myApIkEy\"\nsearch_url = \"https://trove.nla.gov.au/search/category/newspapers?keyword=wragge\"\n\n# Convert the search url into a set of API parameters\nmy_query_params = prepare_query(search_url)\n\n# Initialise the Harvester\nharvester = Harvester(query_params=myquery_params, key=my_api_key)\n\n# Start the harvest\nharvester.harvest()\nIf you want to harvest the OCRd text of articles as well as metadata, add text=True to the harvester initialisation.\n# Initialise the Harvester\nharvester = Harvester(query_params=myquery_params, key=my_api_key, text=True)\nSimilarly you can harvest PDFs and images of articles by adding pdf=True and image=True to the harvester initialisation, but keep in mind that these options will make the harvest much slower!\nYou can generate a set of query parameters from a Trove search url using prepare_query().\n\n# TEST FOR MISSING PARAMETERS\n# You need to supply either query_params AND key, OR config_file. \n# If you don't you'll get a NoQueryError\nwith ExceptionExpected(ex=NoQueryError):\n    harvester = Harvester()\n\n\nsource\n\n\nprepare_query\n\n prepare_query (query)\n\nConverts a Trove search url into a set of parameters ready for harvesting.\nParameters:\n\nquery [required, search url from Trove web interface or API, string]\n\nReturns:\n\na dictionary of parameters\n\nThe prepare_query function converts a search url from the Trove web interface or API into a set of parameters that you can feed to Harvester. It uses the trove-query-parser to do most of the work, but adds in a few extra parameters needed for the harvest.\n\nquery_params = prepare_query(\"https://trove.nla.gov.au/search/category/newspapers?keyword=wragge&l-state=New%20South%20Wales&l-artType=newspapers&l-title=508&l-decade=191&l-category=Article\"\n)\nquery_params\n\n{'q': 'wragge',\n 'l-state': ['New South Wales'],\n 'l-artType': 'newspapers',\n 'l-title': ['508'],\n 'l-decade': ['191'],\n 'l-category': ['Article'],\n 'category': 'newspaper',\n 'encoding': 'json',\n 'reclevel': 'full',\n 'bulkHarvest': 'true'}\n\n\n\n# TEST query_params()\n# Convert a url from the Trove web interface\nquery_params = prepare_query(\n    \"https://trove.nla.gov.au/search/category/newspapers?keyword=wragge\"\n)\n\n# Test the results\nassert query_params == {\n    \"q\": \"wragge\",\n    \"category\": \"newspaper\",\n    \"encoding\": \"json\",\n    \"reclevel\": \"full\",\n    \"bulkHarvest\": \"true\",\n}\n\n# Convert a url from an API request\nquery_params = prepare_query(\n    \"https://api.trove.nla.gov.au/v2/result?q=wragge&category=newspaper&encoding=json&l-category=Article\"\n)\n\nassert query_params == {\n    \"q\": [\"wragge\"],\n    \"category\": [\"newspaper\"],\n    \"encoding\": \"json\",\n    \"l-category\": [\"Article\"],\n    \"reclevel\": \"full\",\n    \"bulkHarvest\": \"true\",\n}\n\n\n\nInitialising a harvest using a harvester_config.json file\nThe parameters used to initialise a harvest are saved into a file called harvester_config.json. This provides useful documentation of your harvest, making it possible to reconstruct the process at a later date.\nFor example, you might want to re-harvest a particular query a year after your initial harvest to see how the results have changed. Remember, more articles are being added every week! To re-run a harvest, just point the Harvester to the harvester_config.json file. By default, your new harvest will be saved in a fresh directory.\nfrom trove_newspaper_harvester.core import Harvester\n\nharvester = Harvester(config_file=\"path/to/old/harvest/harvester_config.json\")\n\nharvester.harvest()\nNote that the harvester_config.json contains all the parameters used for your harvest, including your Trove API key. This makes it easy to re-run a harvest at a later date, but if you’re intending to share your harvest results you should delete or obscure the key value.\n\n# TEST: Reharvest from config file\n\nAPI_KEY = os.getenv(\"TROVE_API_KEY\")\n\ntest_config = {\n    'query_params': {'q': 'wragge',\n    'l-state': ['Western Australia'],\n    'l-illustrated': 'true',\n    'l-illtype': ['Photo'],\n    'include': ['articleText'],\n    'category': 'newspaper',\n    'encoding': 'json',\n    'reclevel': 'full',\n    'bulkHarvest': 'true'},\n    'key': API_KEY,\n    'full_harvest_dir': 'harvests/test_harvest',\n    'maximum': None,\n    'text': True,\n    'pdf': False,\n    'image': False,\n    'include_linebreaks': False\n}\n\nPath(\"harvester_config.json\").write_text(json.dumps(test_config))\n\n# Initialise the harvester\nharvester = Harvester(config_file=\"harvester_config.json\")\n\n# Start the harvest!\nharvester.harvest()\n\nshutil.rmtree(Path(\"data\"))\nPath(\"harvester_config.json\").unlink()\n\n\n\n\n\n\nWhere your harvests are saved\nBy default, harvests are saved in a directory named data. Each individual harvest is saved in a directory named according to the current date/time, for example: data/20230826125205.\n\n# TEST HARVESTER CREATES DEFAULT HARVEST DIRECTORY\n# This example initialises a harvest, but doesn't actually run it.\n\nAPI_KEY = os.getenv(\"TROVE_API_KEY\")\n\n# Prepare query params\nquery_params = prepare_query(\n    \"https://trove.nla.gov.au/search/category/newspapers?keyword=wragge\"\n)\n\n# Initialise the Harvester with the query parameters\nharvester = Harvester(query_params=query_params, key=API_KEY, text=True)\n\n# if you haven't set the max parameter, the total value will be the total number of results\nassert harvester.total &gt; 0\nprint(f\"Total results: {harvester.total:,}\")\n\n# Check that the data directory exists\nassert Path(\"data\").exists() is True\n\n# Check that a harvest directory with the current date/hour exists in the data directory\nassert len(list(Path(\"data\").glob(f'{arrow.utcnow().format(\"YYYYMMDDHH\")}*'))) == 1\n\n# Check that a 'text' directory exists in the harvest directory\nassert (\n    Path(next(Path(\"data\").glob(f'{arrow.utcnow().format(\"YYYYMMDDHH\")}*'))).exists()\n    is True\n)\n\n# Check that the cache has been initialised\nassert Path(f\"{'-'.join(harvester.harvest_dir.parts)}.sqlite\").exists()\n\n# Clean up\nshutil.rmtree(Path(\"data\"))\nharvester.delete_cache()\n\nTotal results: 140,806\n\n\nYou can change the default directories using the data_dir and harvest_dir parameters. For example, if you wanted to keep all the harvests relating to a specific project together, you could set data_dir=\"my-cool-project\". You can use harvest_dir to give your harvest a meaningful name, for example harvest_dir=\"search-for-cat-photos\".\n\n# TEST HARVESTER CREATES REQUESTED HARVEST DIRECTORY\n\nquery_params = prepare_query(\n    \"https://trove.nla.gov.au/search/category/newspapers?keyword=wragge\"\n)\n\nharvester = Harvester(\n    query_params=query_params,\n    key=API_KEY,\n    data_dir=\"harvests\",\n    harvest_dir=\"my_trove_harvest\",\n    pdf=True,\n    image=True,\n)\n\nassert harvester.total &gt; 0\nprint(f\"Total results: {harvester.total:,}\")\n\n# Check that the data directory exists\nassert Path(\"harvests\").exists() is True\n\nassert Path(\"harvests\", \"my_trove_harvest\").exists() is True\n\nassert Path(\"harvests\", \"my_trove_harvest\", \"pdf\").exists() is True\n\nassert Path(\"harvests\", \"my_trove_harvest\", \"image\").exists() is True\n\n# Clean up\nshutil.rmtree(Path(\"harvests\"))\nharvester.delete_cache()\n\nTotal results: 140,806\n\n\n\nsource\n\n\nHarvester.harvest\n\n Harvester.harvest ()\n\nStart the harvest and loop over the result set until finished.\nOnce the harvester is initialised, you can start the harvest by calling Harvester.harvest(). A progress bar will keep you informed of the status of your harvest.\nAdd text=True to include the OCRd full text of the articles in the harvest. The contents of each article is saved as a separate file in the text directory. See the harvest results section below for more information.\n\n# HARVEST WITH TEXT &gt; 100 records\n\n# Prepare query parameters\nquery_params = prepare_query(\n    \"https://trove.nla.gov.au/search/category/newspapers?keyword=wragge&l-state=Western%20Australia&l-illustrationType=Photo\"\n)\n\n# Initialise the harvester\nharvester = Harvester(\n    query_params=query_params,\n    key=API_KEY,\n    data_dir=\"harvests\",\n    harvest_dir=\"test_harvest\",\n    text=True,\n)\n\n# Start the harvest\nharvester.harvest()\n\n\n# ---TESTS---\n# Check that the ndjson file exists and lines can be parsed as json\njson_data = []\nwith harvester.ndjson_file.open(\"r\") as ndjson_file:\n    for line in ndjson_file:\n        json_data.append(json.loads(line.strip()))\n\n# The length of the ndjson file should equal the number of records harvested\nassert len(json_data) == harvester.harvested\n\n# Check that the metadata file has been created\nconfig = get_config(harvester.harvest_dir)\nassert config[\"query_params\"] == query_params\n\n# Check that the RO-Crate file was created\ncrate = get_crate(harvester.harvest_dir)\neids = [\n    \"./\", \n    \"ro-crate-metadata.json\", \n    \"#harvester_run\", \n    \"harvester_config.json\", \n    \"https://github.com/wragge/trove-newspaper-harvester\",\n    \"results.ndjson\",\n    \"text\",\n    \"https://creativecommons.org/publicdomain/zero/1.0/\",\n    \"http://rightsstatements.org/vocab/CNE/1.0/\",\n    \"http://rightsstatements.org/vocab/NKC/1.0/\" \n]\nfor eid in eids:\n    assert crate.get(eid) is not None\n\n# Check that a text file exists and can be read\nassert Path(\"harvests\", \"test_harvest\", json_data[0][\"articleText\"]).exists()\ntext = Path(\"harvests\", \"test_harvest\", json_data[0][\"articleText\"]).read_text()\nassert isinstance(text, str)\n\n# Check that the cache file was deleted\nassert Path(f\"{'-'.join(harvester.harvest_dir.parts)}.sqlite\").exists() is False\n\nshutil.rmtree(Path(\"harvests\"))\n\n\n\n\nThe text of articles in the Australian Women’s Weekly is not available through the API, so the harvester has to scrape it separately. This happens automatically. The code below is just a little test to make sure it’s working as expected.\n\n# ---TEST FOR AWW---\n# Prepare query params\nquery_params = prepare_query(\n    \"https://trove.nla.gov.au/search/category/newspapers?keyword=wragge\"\n)\n\n# Initialise the Harvester with the query parameters\nharvester = Harvester(query_params=query_params, key=API_KEY, text=True)\n\n# Get html text of an article\ntext = harvester.get_aww_text(51187457)\nassert \"THE SHAPE OF THINGS TO COME\" in text\n\n# Clean up\nharvester.delete_cache()\nshutil.rmtree(Path(\"data\"))\n\nYou can include PDFs and images of the articles by adding pdf=True or image=True to the harvester initialisation. It’s important to note that this will slow down the harvest a lot, as each file needs to be generated and downloaded individually.\n\n# HARVEST WITH PDF AND IMAGE -- 1 RECORD MAX\n\n# Prepare the query parameters\nquery_params = prepare_query(\n    \"https://trove.nla.gov.au/search/category/newspapers?keyword=wragge&l-illustrationType=Cartoon\"\n)\n\n# Initialise the harvester\nharvester = Harvester(\n    query_params=query_params,\n    key=API_KEY,\n    data_dir=\"harvests\",\n    harvest_dir=\"test_harvest\",\n    pdf=True,\n    image=True,\n    maximum=1,\n)\n\n# Start the harvest!\nharvester.harvest()\n\n\n# ---TESTS---\n\n# Check that the ndjson file exists and lines can be parsed as json\njson_data = []\nwith harvester.ndjson_file.open(\"r\") as ndjson_file:\n    for line in ndjson_file:\n        json_data.append(json.loads(line.strip()))\n\nassert harvester.maximum == harvester.harvested\n\n# The length of the ndjson file should equal the number of records harvested\nassert len(json_data) == harvester.harvested\n\n# Check that a pdf and image file exist\nassert Path(\"harvests\", \"test_harvest\", json_data[0][\"pdf\"]).exists()\nassert Path(\"harvests\", \"test_harvest\", json_data[0][\"images\"][0]).exists()\n\nshutil.rmtree(Path(\"harvests\"))\n\n\n\n\nNaturally enough, nothing is harvested from a query with no results. Check your search and your API key!\n\n# HARVEST WITH NO RESULTS\n\n# Prepare query parameters\nquery_params = prepare_query(\n    \"https://trove.nla.gov.au/search/category/newspapers?keyword=wwgagsgshggshghso\"\n)\n\n# Initialise the harvester\nharvester = Harvester(\n    query_params=query_params,\n    key=API_KEY\n)\n\n# Start the harvest\nharvester.harvest()\n\nassert harvester.harvested == 0\nshutil.rmtree(Path(\"data\"))\n\n\n\nRestarting a failed harvest\nThe Harvester uses requests-cache to cache API responses. This makes it easy to restart a failed harvest. All you need to do is call Harvester.harvest() again and it will pick up where it left off.\n\nsource\n\n\nHarvester.save_csv\n\n Harvester.save_csv ()\n\nFlatten and rename data in the ndjson file to save as CSV.\nHarvested metadata is saved, by default, in a newline-delimited JSON file. If you’d prefer the results in CSV format, just call Harvester.save_csv(). See below for more information on results formats.\n\n# TEST - save harvest results as CSV\n\n# Prepare query parameters\nquery_params = prepare_query(\n    \"https://trove.nla.gov.au/search/category/newspapers?keyword=wragge&l-state=Western%20Australia&l-illustrationType=Photo\"\n)\n\n# Initialise the harvester\nharvester = Harvester(\n    query_params=query_params,\n    key=API_KEY,\n    data_dir=\"harvests\",\n    harvest_dir=\"test_harvest\",\n    text=True,\n)\n\n# Start the harvest\nharvester.harvest()\n\n# Save results as CSV\nharvester.save_csv()\n\n# ---TESTS---\n\n# Check that CSV file exists\ncsv_file = Path(harvester.harvest_dir, \"results.csv\")\nassert csv_file.exists()\n\n# Open the CSV file and check that the number of rows equals number of records harvested\ndf = pd.read_csv(csv_file)\nassert df.shape[0] == harvester.harvested\n\nshutil.rmtree(Path(\"harvests\"))\n\n\n\n\n\n\nHarvest results\nThere will be at least three files created for each harvest:\n\nharvester_config.json a file that captures the parameters used to launch the harvest\nro-crate-metadata.json a metadata file documenting the harvest in RO-Crate format\nresults.ndjson contains details of all the harvested articles in a newline delimited JSON format (each line is a JSON object)\n\nThe results.ndjson stores the API results from Trove as is, with a couple of exceptions:\n\nif the text parameter has been set to True, the articleText field will contain the path to a .txt file containing the OCRd text contents of the article (rather than containing the text itself)\nsimilarly if PDFs and images are requests, the pdf and image fields int the ndjson file will point to the saved files.\n\nYou’ll probably find it easier to work with the results in CSV format. The Harvester.save_csv() method flattens the ndjson file and renames some columns to make them compatible with previous versions of the harvest. It produces a results.csv file, which is a plain text CSV (Comma Separated Values) file. You can open it with any spreadsheet program. The details recorded for each article are:\n\narticle_id – a unique identifier for the article\ntitle – the title of the article\ndate – in ISO format, YYYY-MM-DD\npage – page number (of course), but might also indicate the page is part of a supplement or special section\nnewspaper_id – a unique identifier for the newspaper or gazette title (this can be used to retrieve more information or build a link to the web interface)\nnewspaper_title – the name of the newspaper (or gazette)\ncategory – one of ‘Article’, ‘Advertising’, ‘Detailed lists, results, guides’, ‘Family Notices’, or ‘Literature’\nwords – number of words in the article\nillustrated – is it illustrated (values are y or n)\nedition – edition of newspaper (rarely used)\nsupplement – section of newspaper (rarely used)\nsection – section of newspaper (rarely used)\nurl – the persistent url for the article\npage_url – the persistent url of the page on which the article is published\nsnippet – short text sample\nrelevance – search relevance score of this result\nstatus – some articles that are still being processed will have the status “coming soon” and might be missing other fields\ncorrections – number of text corrections\nlast_correction – date of last correction\ntags – number of attached tags\ncomments – number of attached comments\nlists – number of lists this article is included in\ntext – path to text file\npdf – path to PDF file\nimage – path to image file\n\nIf you’ve asked for text files PDFs or images, there will be additional directories containing those files. Files containing the OCRd text of the articles will be saved in a directory named text. These are just plain text files, stripped on any HTML. These files include some basic metadata in their file titles – the date of the article, the id number of the newspaper, and the id number of the article. So, for example, the filename 19460104-1002-206680758.txt tells you:\n\n19460104 – the article was published on 4 January 1946 (YYYYMMDD)\n1002 – the article was published in The Tribune\n206680758 – the article’s unique identifier\n\nAs you can see, you can use the newspaper and article ids to create direct links into Trove:\n\nto a newspaper or gazette https://trove.nla.gov.au/newspaper/title/[newspaper id]\nto an article http://nla.gov.au/nla.news-article[article id]\n\nSimilarly, if you’ve asked for copies of the articles as images, they’ll be in a directory named image. The image file names are similar to the text files, but with an extra id number for the page from which the image was extracted. So, for example, the image filename 19250411-460-140772994-11900413.jpg tells you:\n\n19250411 – the article was published on 11 April 1925 (YYYYMMDD)\n460 – the article was published in The Australasian\n140772994 – the article’s unique identifier\n11900413 – the page’s unique identifier (some articles can be split over multiple pages)\n\nThe text of articles in the Australian Women’s Weekly is not available through the API, so the harvester has to scrape it separately. This happens automatically. The code below is just a little test to make sure it’s working as expected.\n\nsource\n\n\nget_harvest\n\n get_harvest (data_dir='data', harvest_dir=None)\n\nGet the path to a harvest. If data_dir and harvest_dir are not supplied, this will return the most recent harvest in the ‘data’ directory.\nParameters:\n\ndata_dir [optional, directory for harvests, string]\nharvest_dir [optional, directory for this harvest, string]\n\nReturns:\n\na pathlib.Path object pointing to the harvest directory\n\n\n# TEST GET HARVEST\n\n# Create test folders\nPath(\"data\", \"20220919100000\").mkdir(parents=True)\nPath(\"data\", \"20220919200000\").mkdir(parents=True)\n\n# Get latest harvest folder\nharvest = get_harvest()\nprint(harvest)\n\n# ---TESTS---\nassert harvest.name == \"20220919200000\"\n\nharvest = get_harvest(data_dir=\"data\", harvest_dir=\"20220919100000\")\nassert harvest.name == \"20220919100000\"\n\nshutil.rmtree(Path(\"data\"))\n\ndata/20220919200000\n\n\n\nsource\n\n\nget_config\n\n get_config (harvest)\n\nGet the query config parameters from a harvest directory.\nParameters:\n\nharvest [required, path to harvest, string or pathlib.Path]\n\nReturns:\n\nconfig dictionary\n\nThe harvester_config.json file contains the parameters used to initiate a harvest. Using get_config you can retrieve the harvester_config.json for for a particular harvest. This can be useful if, for example, you want to re-run a harvest at a later data – you can just grab the query_paramaters and feed them into a new Harvester instance.\n\n# Prepare query parameters\nquery_params = prepare_query(\n    \"https://trove.nla.gov.au/search/category/newspapers?keyword=wragge&l-state=Western%20Australia&l-illustrationType=Photo\"\n)\n\n# Initialise the harvester\nharvester = Harvester(\n    query_params=query_params,\n    key=API_KEY,\n    text=True,\n)\n\n# Start the harvest\nharvester.harvest()\n\n# Get the most recent harvest\nharvest = get_harvest()\n\n# Get the metadata\nconfig = get_config(harvest)\n\n# Obscure key and display\nconfig[\"key\"] = \"########\"\ndisplay(config)\n\n# ---TESTS---\nassert config[\"query_params\"][\"q\"] == \"wragge\"\nassert config[\"text\"] is True\n\nshutil.rmtree(Path(\"data\"))\n\n\n\n\n{'query_params': {'q': 'wragge',\n  'l-state': ['Western Australia'],\n  'l-illustrated': 'true',\n  'l-illustrationType': ['Photo'],\n  'category': 'newspaper',\n  'encoding': 'json',\n  'reclevel': 'full',\n  'bulkHarvest': 'true',\n  'include': ['articleText']},\n 'key': '########',\n 'full_harvest_dir': 'data/20231023042615',\n 'maximum': None,\n 'text': True,\n 'pdf': False,\n 'image': False,\n 'include_linebreaks': False}\n\n\n\nsource\n\n\nget_crate\n\n get_crate (harvest)\n\nGet the RO-Crate metadata file from a harvest directory.\nParameters:\n\nharvest [required, path to harvest, string or pathlib.Path]\n\nReturns:\n\nROCrate object\n\nTrove is changing all the time, so it’s important to document your harvests. The Harvester automatically creates a metadata file using the Research Object Crate (RO-Crate) format. This documents when the harvest was run, how many results were saved, and the version of the harvester. It is linked to the harvester_config.json file that save the query parameters and harvester settings. This function retrieves the RO-Crate file for a given harvest. It returns an RO-Crate object – see the ro-crate.py package for more information.\n\n# Prepare query parameters\nquery_params = prepare_query(\n    \"https://trove.nla.gov.au/search/category/newspapers?keyword=wragge&l-state=Western%20Australia&l-illustrationType=Photo\"\n)\n\n# Initialise the harvester\nharvester = Harvester(\n    query_params=query_params,\n    key=API_KEY,\n    text=True,\n)\n\n# Start the harvest\nharvester.harvest()\n\n# Get the most recent harvest\nharvest = get_harvest()\n\n# Get the metadata\ncrate = get_crate(harvest)\n\nfor eid in crate.get_entities():\n    print(eid.id, eid.type)\n\nassert crate.get(\"./\").type == \"Dataset\"\nassert crate.get(\"harvester_config.json\").properties()[\"encodingFormat\"] == \"application/json\"\nassert crate.get(\"./\").properties()[\"mainEntity\"] == {\"@id\": \"#harvester_run\"}\n\nshutil.rmtree(Path(\"data\"))\n\n\n\n\n./ Dataset\nro-crate-metadata.json CreativeWork\nharvester_config.json File\nresults.ndjson ['File', 'Dataset']\ntext ['File', 'Dataset']\n#harvester_run CreateAction\nhttps://github.com/wragge/trove-newspaper-harvester SoftwareApplication\nhttp://rightsstatements.org/vocab/NKC/1.0/ CreativeWork\nhttp://rightsstatements.org/vocab/CNE/1.0/ CreativeWork\nhttps://creativecommons.org/publicdomain/zero/1.0/ CreativeWork\n\n\n\nsource\n\n\nNoQueryError\nException triggered by empty query.\n\nCreated by Tim Sherratt for the GLAM Workbench. Support this project by becoming a GitHub sponsor."
  },
  {
    "objectID": "cli.html",
    "href": "cli.html",
    "title": "cli",
    "section": "",
    "text": "Before you do any harvesting you need to get yourself a Trove API key.\nThere are three basic commands:"
  },
  {
    "objectID": "cli.html#functions",
    "href": "cli.html#functions",
    "title": "cli",
    "section": "Functions",
    "text": "Functions\nThe functions below are all called by the command-line interface, so don’t need to be accessed directly. See the core library for programmatic access to the Harvester class.\n\nsource\n\nstart_harvest\n\n start_harvest (query=None, key=None, config_file=None, data_dir='data',\n                harvest_dir=None, text=False, pdf=False, image=False,\n                include_linebreaks=False, max=None, keep_json=False)\n\nStart a harvest. Note that you must supply either query_params and key or config_file.\nParameters:\n\nquery [optional, search url from Trove web interface or API, string]\nkey [optional, Trove API key, string]\nconfig_file [optional, path to a config file]\ndata_dir [optional, directory for harvests, string]\nharvest_dir [optional, directory for this harvest, string]\ntext [optional, save articles as text files, True or False]\npdf [optional, save articles as PDFs, True or False]\nimage [optional, save articles as images, True or False]\ninclude_linebreaks [optional, include linebreaks in text files, True or False]\nmax [optional, maximum number of results, integer]\nkeep_json [optional, keep the results.ndjson file, true or False]\n\n\n# Test for missing query\nAPI_KEY = os.getenv(\"TROVE_API_KEY\")\n\n\ndef test_no_query():\n    start_harvest(\"\", API_KEY)\n\n\ntest_stdout(test_no_query, \"No query parameters found, check your query url. You must supply either a query and key, or a config_file.\")\n\n\nstart_harvest(\n    \"https://trove.nla.gov.au/search/category/newspapers?keyword=wragge&l-state=Western%20Australia&l-illustrationType=Photo\",\n    API_KEY,\n    text=True,\n)\n\nthis_harvest = get_harvest()\n\nassert Path(this_harvest, \"results.csv\").exists() is True\nassert Path(this_harvest, \"results.ndjson\").exists() is False\nassert Path(this_harvest, \"text\").exists() is True\n\nshutil.rmtree(Path(\"data\"))\n\n\n\n\n\nstart_harvest(\n    \"https://trove.nla.gov.au/search/category/newspapers?keyword=wragge&l-state=Western%20Australia&l-illustrationType=Photo\",\n    API_KEY,\n    text=True,\n    keep_json=True,\n)\n\nthis_harvest = get_harvest()\n\nassert Path(this_harvest, \"results.csv\").exists() is True\nassert Path(this_harvest, \"results.ndjson\").exists() is True\nassert Path(this_harvest, \"text\").exists() is True\n\n\n\n\n\nsource\n\n\nreport_harvest\n\n report_harvest (data_dir='data', harvest_dir=None)\n\nProvide some details of a harvest. If no harvest is specified, show the most recent.\nParameters:\n\ndata_dir [optional, directory for harvests, string]\nharvest_dir [optional, directory for this harvest, string]\n\n\nreport_harvest()\n\n\nHARVEST PARAMETERS\n==================\nHarvest path: data/20230826123318\nQuery parameters:\n{ 'bulkHarvest': 'true',\n  'category': 'newspaper',\n  'encoding': 'json',\n  'include': ['articleText'],\n  'l-illtype': ['Photo'],\n  'l-illustrated': 'true',\n  'l-state': ['Western Australia'],\n  'q': 'wragge',\n  'reclevel': 'full'}\nMax results: None\nInclude PDFs: False\nInclude text: True\nInclude images: False\nInclude linebreaks: False\n\nHARVEST RESULTS\n===============\nHarvest started: 2023-08-26T22:33:18.881889+10:00\nHarvest ended: 2023-08-26T22:33:25.034403+10:00\nTotal articles: 174\nHarvested by: Trove Newspaper and Gazette Harvester version 0.7.0\n\n\n\n# TEST REPORT\ntest_stdout(report_harvest, \"^\\nHARVEST PARAMETERS.*\", regex=True)\ntest_stdout(report_harvest, \"HARVEST RESULTS.*\", regex=True)\nshutil.rmtree(Path(\"data\"))\n\n\nsource\n\n\nrestart_harvest\n\n restart_harvest (data_dir='data', harvest_dir=None)\n\nRestart a failed harvest.\nParameters:\n\ndata_dir [optional, directory for harvests, string]\nharvest_dir [optional, directory for this harvest, string]\n\n\n# TEST RESTART\n# To test the restart function we'll create a new harvester but not start it\nparams = prepare_query(\n    query=\"https://trove.nla.gov.au/search/category/newspapers?keyword=wragge&l-state=Western%20Australia&l-illustrationType=Photo\"\n)\nharvester = Harvester(query_params=params, key=API_KEY, text=True)\n\n# Should be no data yet\nassert harvester.ndjson_file.exists() is False\n\n# The cache should still exist\nassert Path(f\"{'-'.join(harvester.harvest_dir.parts)}.sqlite\").exists()\n\n# Now it should run with restart using the settings from above\nrestart_harvest()\n\n# Should be data now\nassert harvester.ndjson_file.exists() is True\n\n# The cache should have been deleted\nassert Path(f\"{'-'.join(harvester.harvest_dir.parts)}.sqlite\").exists() is False\n\n# Clean up\nshutil.rmtree(Path(\"data\"))\n\n\n\n\n\nsource\n\n\nmain\n\n main ()\n\nSets up the command-line interface\n\nCreated by Tim Sherratt for the GLAM Workbench. Support this project by becoming a GitHub sponsor."
  }
]