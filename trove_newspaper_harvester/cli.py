# AUTOGENERATED! DO NOT EDIT! File to edit: ../01_cli.ipynb.

# %% auto 0
__all__ = ['start_harvest', 'restart_harvest', 'report_harvest', 'main']

# %% ../01_cli.ipynb 4
import argparse
from pathlib import Path
from pprint import pprint

from requests.exceptions import HTTPError

from trove_newspaper_harvester.core import (
    Harvester,
    NoQueryError,
    get_harvest,
    get_metadata,
    prepare_query,
)

# %% ../01_cli.ipynb 5
def start_harvest(
    query,
    key,
    data_dir="data",
    harvest_dir=None,
    text=False,
    pdf=False,
    image=False,
    include_linebreaks=False,
    max=None,
    keep_json=False,
):
    """
    Start a harvest.

    Parameters:

    * `query` [required, search url from Trove web interface or API, string]
    * `key` [required, Trove API key, string]
    * `data_dir` [optional, directory for harvests, string]
    * `harvest_dir` [optional, directory for this harvest, string]
    * `text` [optional, save articles as text files, True or False]
    * `pdf` [optional, save articles as PDFs, True or False]
    * `image` [optional, save articles as images, True or False]
    * `include_linebreaks` [optional, include linebreaks in text files, True or False]
    * `max` [optional, maximum number of results, integer]
    * `keep_json` [optional, keep the results.ndjson file, true or False]

    """
    # Turn the query url into a dictionary of parameters
    params = prepare_query(query, key, text=text)
    # Create the harvester
    try:
        harvester = Harvester(
            query_params=params,
            data_dir=data_dir,
            harvest_dir=harvest_dir,
            pdf=pdf,
            text=text,
            image=image,
            include_linebreaks=include_linebreaks,
            max=max,
        )
    except HTTPError as e:
        if e.response.status_code == 403:
            print("The request could not be authorised, check your API key.")
        else:
            raise
    except NoQueryError:
        print("No query parameters found, check your query url.")
    else:
        # Go!
        try:
            harvester.harvest()
        except AttributeError:
            pass
        else:
            if harvester.maximum > 0:
                harvester.save_csv()
                if not keep_json:
                    Path(harvester.harvest_dir, "results.ndjson").unlink()


def restart_harvest(data_dir="data", harvest_dir=None):
    """
    Restart a failed harvest.

    Parameters:

    * `data_dir` [optional, directory for harvests, string]
    * `harvest_dir` [optional, directory for this harvest, string]
    """
    if data_dir and harvest_dir:
        harvest = get_harvest(data_dir=data_dir, harvest_dir=harvest_dir)
    else:
        harvest = get_harvest()
    if Path(f"{'-'.join(harvest.parts)}.sqlite").exists():
        data_dir, harvest_dir = harvest.parts
        meta = get_metadata(harvest)
        if meta:
            harvester = Harvester(
                data_dir=data_dir,
                harvest_dir=harvest_dir,
                query_params=meta["query_parameters"],
                pdf=meta["pdf"],
                text=meta["text"],
                image=meta["image"],
                include_linebreaks=meta["include_linebreaks"],
                max=meta["max"],
            )
            harvester.harvest()


def report_harvest(data_dir="data", harvest_dir=None):
    """
    Provide some details of a harvest.
    If no harvest is specified, show the most recent.

    Parameters:

    * `data_dir` [optional, directory for harvests, string]
    * `harvest_dir` [optional, directory for this harvest, string]
    """
    harvest = get_harvest(data_dir=data_dir, harvest_dir=harvest_dir)
    meta = get_metadata(harvest)
    if meta:
        # results = get_results(data_dir)
        print("")
        print("HARVEST METADATA")
        print("================")
        print(f"Last harvest started: {meta['date_started']}")
        print(f"Harvest id: {meta['harvest_directory']}")
        print("Query parameters:")
        pprint(meta["query_parameters"], indent=2)
        print(f"Max results: {meta['max']}")
        print(f"Include PDFs: {meta['pdf']}")
        print(f"Include text: {meta['text']}")
        print(f"Include images: {meta['image']}")
        print(f"Include linebreaks: {meta['include_linebreaks']}")
        print(f"Harvested with: {meta['harvester']}")


# CLI


def main():
    """
    Sets up the command-line interface
    """
    parser = argparse.ArgumentParser(prog="troveharvester")
    subparsers = parser.add_subparsers(dest="action")
    parser_start = subparsers.add_parser("start", help="start a new harvest")
    parser_start.add_argument("query", help="url of the search you want to harvest")
    parser_start.add_argument("key", help="Your Trove API key")
    parser_start.add_argument(
        "--data_dir", default="data", help="directory for harvests"
    )
    parser_start.add_argument("--harvest_dir", help="directory for this harvest")
    parser_start.add_argument(
        "--max", type=int, default=0, help="maximum number of results to return"
    )
    parser_start.add_argument(
        "--pdf", action="store_true", help="save PDFs of articles"
    )
    parser_start.add_argument(
        "--text", action="store_true", help="save text contents of articles"
    )
    parser_start.add_argument(
        "--image", action="store_true", help="save images of articles"
    )
    parser_start.add_argument(
        "--include_linebreaks",
        action="store_true",
        help="preserve line breaks in text files",
    )
    parser_start.add_argument(
        "--keep_json", action="store_true", help="keep the raw ndjson results file"
    )
    parser_restart = subparsers.add_parser(
        "restart", help="restart an unfinished harvest"
    )
    parser_restart.add_argument("--data_dir", help="directory for harvests")
    parser_restart.add_argument("--harvest_dir", help="directory for this harvest")
    parser_report = subparsers.add_parser("report", help="report on a harvest")
    parser_report.add_argument("--data_dir", help="directory for harvests")
    parser_report.add_argument("--harvest_dir", help="directory for this harvest")
    args = parser.parse_args()
    if args.action == "report":
        report_harvest(
            data_dir=args.data_dir,
            harvest_dir=args.harvest_dir,
        )
    elif args.action == "restart":
        restart_harvest(
            data_dir=args.data_dir,
            harvest_dir=args.harvest_dir,
        )
    elif args.action == "start":
        start_harvest(
            query=args.query,
            key=args.key,
            data_dir=args.data_dir,
            harvest_dir=args.harvest_dir,
            text=args.text,
            pdf=args.pdf,
            image=args.image,
            include_linebreaks=args.include_linebreaks,
            keep_json=args.keep_json,
            max=args.max,
        )
